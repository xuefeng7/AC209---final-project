{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/weihangzhang/AC209---final-project/src'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data keys: ['images', 'labels', 'observation_days']\n"
     ]
    }
   ],
   "source": [
    "data = h5py.File(\"./data_sample.hdf5\", \"r\")\n",
    "print(\"data keys: \"+str(list(data.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: (sample, x_size, y_size, epoch) = (72000, 21, 21, 48)\n"
     ]
    }
   ],
   "source": [
    "images = data[\"images\"][:]\n",
    "print(\"image shape: (sample, x_size, y_size, epoch) = \"+str(images.shape))\n",
    "labels = data[\"labels\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'Asteroids':0, 'Constant':1, 'EmptyLigh':2, 'M33Cephei':3, 'RRLyrae':4, 'Supernova':5}\n",
    "labels_digit = [dic[i] for i in labels]\n",
    "# print(labels_digit)\n",
    "\n",
    "# labels_flatten = np.repeat(labels_digit, 48)\n",
    "enc = OneHotEncoder()\n",
    "labels_onehot = enc.fit_transform(np.array(labels_digit).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72000, 6)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72000, 21, 21, 48)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten_data = images.transpose(0, 3, 1, 2).reshape((72000*48, 21, 21, 1))\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_idx = np.random.choice(range(len(flatten_data)), 100000)\n",
    "# sample_data = flatten_data[sample_idx]\n",
    "# sample_labels = labels_flatten_onehot[sample_idx]\n",
    "# sample_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_val, y_train, y_val = train_test_split(sample_data, sample_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75000, 21, 21, 1), (75000, 6))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(48, (4,4), input_shape=(21,21,48), padding='same', activation='relu', kernel_initializer='uniform'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling2D((3,3), strides=(1,1)))\n",
    "    \n",
    "    model.add(Conv2D(24, (3,3), padding='same', activation='relu', kernel_initializer='uniform'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling2D((3,3), strides=(1,1)))\n",
    "\n",
    "    model.add(Conv2D(12, (3,3), padding='same', activation='relu', kernel_initializer='uniform'))\n",
    "    model.add(MaxPooling2D((3,3), strides=(1,1)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "#     model.add(Dense(256, activation='relu'))\n",
    "#     model.add(Dropout(0.25))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_90 (Conv2D)           (None, 21, 21, 48)        36912     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_69 (MaxPooling (None, 19, 19, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 19, 19, 24)        10392     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_70 (MaxPooling (None, 17, 17, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_92 (Conv2D)           (None, 17, 17, 12)        2604      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_71 (MaxPooling (None, 15, 15, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 2700)              0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 128)               345728    \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 396,410\n",
      "Trainable params: 396,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# model = init_model()\n",
    "print(model.summary())\n",
    "adam = keras.optimizers.Adam(lr=0.00001)#, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57600 samples, validate on 14400 samples\n",
      "Epoch 1/60\n",
      "57600/57600 [==============================] - 9s 159us/step - loss: 0.4900 - acc: 0.7955 - val_loss: 0.4949 - val_acc: 0.7994\n",
      "Epoch 2/60\n",
      "57600/57600 [==============================] - 9s 158us/step - loss: 0.4829 - acc: 0.8009 - val_loss: 0.5387 - val_acc: 0.7868\n",
      "Epoch 3/60\n",
      "57600/57600 [==============================] - 9s 161us/step - loss: 0.4921 - acc: 0.7944 - val_loss: 0.5662 - val_acc: 0.7667\n",
      "Epoch 4/60\n",
      "57600/57600 [==============================] - 9s 158us/step - loss: 0.4964 - acc: 0.7948 - val_loss: 0.5033 - val_acc: 0.7955\n",
      "Epoch 5/60\n",
      "57600/57600 [==============================] - 9s 158us/step - loss: 0.4874 - acc: 0.7981 - val_loss: 0.5348 - val_acc: 0.7835\n",
      "Epoch 6/60\n",
      "57600/57600 [==============================] - 9s 159us/step - loss: 0.4803 - acc: 0.8011 - val_loss: 0.5570 - val_acc: 0.7797\n",
      "Epoch 7/60\n",
      "57600/57600 [==============================] - 9s 158us/step - loss: 0.4803 - acc: 0.8020 - val_loss: 0.4914 - val_acc: 0.8019\n",
      "Epoch 8/60\n",
      "57600/57600 [==============================] - 9s 161us/step - loss: 0.4806 - acc: 0.8032 - val_loss: 0.4966 - val_acc: 0.8052\n",
      "Epoch 9/60\n",
      "57600/57600 [==============================] - 9s 156us/step - loss: 0.4774 - acc: 0.8017 - val_loss: 0.5049 - val_acc: 0.7949\n",
      "Epoch 10/60\n",
      "57600/57600 [==============================] - 9s 153us/step - loss: 0.4759 - acc: 0.8040 - val_loss: 0.4692 - val_acc: 0.8128\n",
      "Epoch 11/60\n",
      "57600/57600 [==============================] - 8s 144us/step - loss: 0.4820 - acc: 0.8014 - val_loss: 0.5425 - val_acc: 0.7853\n",
      "Epoch 12/60\n",
      "57600/57600 [==============================] - 8s 146us/step - loss: 0.4800 - acc: 0.8016 - val_loss: 0.5099 - val_acc: 0.7991\n",
      "Epoch 13/60\n",
      "57600/57600 [==============================] - 9s 151us/step - loss: 0.4757 - acc: 0.8053 - val_loss: 0.4880 - val_acc: 0.8022\n",
      "Epoch 14/60\n",
      "57600/57600 [==============================] - 9s 155us/step - loss: 0.4755 - acc: 0.8035 - val_loss: 0.5082 - val_acc: 0.7975\n",
      "Epoch 15/60\n",
      "57600/57600 [==============================] - 9s 153us/step - loss: 0.4726 - acc: 0.8044 - val_loss: 0.4727 - val_acc: 0.8144\n",
      "Epoch 16/60\n",
      "57600/57600 [==============================] - 9s 155us/step - loss: 0.4740 - acc: 0.8045 - val_loss: 0.4740 - val_acc: 0.8100\n",
      "Epoch 17/60\n",
      "57600/57600 [==============================] - 9s 153us/step - loss: 0.4705 - acc: 0.8045 - val_loss: 0.4786 - val_acc: 0.8100\n",
      "Epoch 18/60\n",
      "57600/57600 [==============================] - 9s 152us/step - loss: 0.4752 - acc: 0.8046 - val_loss: 0.4893 - val_acc: 0.8027\n",
      "Epoch 19/60\n",
      "57600/57600 [==============================] - 9s 154us/step - loss: 0.4724 - acc: 0.8076 - val_loss: 0.5028 - val_acc: 0.7990\n",
      "Epoch 20/60\n",
      "57600/57600 [==============================] - 9s 153us/step - loss: 0.4748 - acc: 0.8046 - val_loss: 0.5131 - val_acc: 0.7969\n",
      "Epoch 21/60\n",
      "57600/57600 [==============================] - 9s 154us/step - loss: 0.4710 - acc: 0.8056 - val_loss: 0.4920 - val_acc: 0.8019\n",
      "Epoch 22/60\n",
      "57600/57600 [==============================] - 9s 153us/step - loss: 0.4680 - acc: 0.8072 - val_loss: 0.4671 - val_acc: 0.8160\n",
      "Epoch 23/60\n",
      "57600/57600 [==============================] - 9s 154us/step - loss: 0.4801 - acc: 0.8044 - val_loss: 0.4965 - val_acc: 0.7976\n",
      "Epoch 24/60\n",
      "57600/57600 [==============================] - 9s 156us/step - loss: 0.4675 - acc: 0.8087 - val_loss: 0.4723 - val_acc: 0.8145\n",
      "Epoch 25/60\n",
      "57600/57600 [==============================] - 9s 155us/step - loss: 0.4709 - acc: 0.8082 - val_loss: 0.4623 - val_acc: 0.8190\n",
      "Epoch 26/60\n",
      "57600/57600 [==============================] - 9s 158us/step - loss: 0.4652 - acc: 0.8103 - val_loss: 0.4751 - val_acc: 0.8165\n",
      "Epoch 27/60\n",
      "57600/57600 [==============================] - 9s 151us/step - loss: 0.4832 - acc: 0.8015 - val_loss: 0.4918 - val_acc: 0.8015\n",
      "Epoch 28/60\n",
      "57600/57600 [==============================] - 9s 156us/step - loss: 0.4742 - acc: 0.8043 - val_loss: 0.4864 - val_acc: 0.8065\n",
      "Epoch 29/60\n",
      "57600/57600 [==============================] - 9s 157us/step - loss: 0.4655 - acc: 0.8092 - val_loss: 0.4740 - val_acc: 0.8122\n",
      "Epoch 30/60\n",
      "57600/57600 [==============================] - 9s 153us/step - loss: 0.4695 - acc: 0.8064 - val_loss: 0.4622 - val_acc: 0.8115\n",
      "Epoch 31/60\n",
      "57600/57600 [==============================] - 9s 153us/step - loss: 0.4605 - acc: 0.8102 - val_loss: 0.4731 - val_acc: 0.8114\n",
      "Epoch 32/60\n",
      "57600/57600 [==============================] - 9s 149us/step - loss: 0.4652 - acc: 0.8087 - val_loss: 0.4736 - val_acc: 0.8084\n",
      "Epoch 33/60\n",
      "57600/57600 [==============================] - 8s 144us/step - loss: 0.4606 - acc: 0.8114 - val_loss: 0.4666 - val_acc: 0.8140\n",
      "Epoch 34/60\n",
      "57600/57600 [==============================] - 8s 145us/step - loss: 0.4646 - acc: 0.8097 - val_loss: 0.4829 - val_acc: 0.8107\n",
      "Epoch 35/60\n",
      "57600/57600 [==============================] - 9s 155us/step - loss: 0.4646 - acc: 0.8087 - val_loss: 0.4672 - val_acc: 0.8149\n",
      "Epoch 36/60\n",
      "57600/57600 [==============================] - 9s 156us/step - loss: 0.4600 - acc: 0.8133 - val_loss: 0.4639 - val_acc: 0.8174\n",
      "Epoch 37/60\n",
      "57600/57600 [==============================] - 9s 155us/step - loss: 0.4569 - acc: 0.8127 - val_loss: 0.4660 - val_acc: 0.8190\n",
      "Epoch 38/60\n",
      "57600/57600 [==============================] - 9s 153us/step - loss: 0.4586 - acc: 0.8121 - val_loss: 0.4828 - val_acc: 0.8119\n",
      "Epoch 39/60\n",
      "57600/57600 [==============================] - 9s 152us/step - loss: 0.4585 - acc: 0.8117 - val_loss: 0.4921 - val_acc: 0.8033\n",
      "Epoch 40/60\n",
      "57600/57600 [==============================] - 9s 151us/step - loss: 0.4578 - acc: 0.8146 - val_loss: 0.4714 - val_acc: 0.8130\n",
      "Epoch 41/60\n",
      "57600/57600 [==============================] - 8s 146us/step - loss: 0.4537 - acc: 0.8169 - val_loss: 0.5189 - val_acc: 0.7998\n",
      "Epoch 42/60\n",
      "57600/57600 [==============================] - 9s 155us/step - loss: 0.4547 - acc: 0.8135 - val_loss: 0.4695 - val_acc: 0.8153\n",
      "Epoch 43/60\n",
      "57600/57600 [==============================] - 9s 153us/step - loss: 0.4799 - acc: 0.8040 - val_loss: 0.4652 - val_acc: 0.8201\n",
      "Epoch 44/60\n",
      "57600/57600 [==============================] - 9s 152us/step - loss: 0.4598 - acc: 0.8131 - val_loss: 0.4777 - val_acc: 0.8070\n",
      "Epoch 45/60\n",
      "57600/57600 [==============================] - 9s 149us/step - loss: 0.4503 - acc: 0.8167 - val_loss: 0.5097 - val_acc: 0.7971\n",
      "Epoch 46/60\n",
      "57600/57600 [==============================] - 8s 144us/step - loss: 0.4557 - acc: 0.8145 - val_loss: 0.4875 - val_acc: 0.8094\n",
      "Epoch 47/60\n",
      "57600/57600 [==============================] - 9s 152us/step - loss: 0.4520 - acc: 0.8150 - val_loss: 0.4628 - val_acc: 0.8184\n",
      "Epoch 48/60\n",
      "57600/57600 [==============================] - 9s 152us/step - loss: 0.4501 - acc: 0.8156 - val_loss: 0.4608 - val_acc: 0.8183\n",
      "Epoch 49/60\n",
      "57600/57600 [==============================] - 8s 146us/step - loss: 0.4584 - acc: 0.8119 - val_loss: 0.5140 - val_acc: 0.7925\n",
      "Epoch 50/60\n",
      "57600/57600 [==============================] - 9s 155us/step - loss: 0.4640 - acc: 0.8124 - val_loss: 0.4700 - val_acc: 0.8162\n",
      "Epoch 51/60\n",
      "57600/57600 [==============================] - 9s 157us/step - loss: 0.4632 - acc: 0.8131 - val_loss: 0.4754 - val_acc: 0.8139\n",
      "Epoch 52/60\n",
      "57600/57600 [==============================] - 9s 154us/step - loss: 0.4425 - acc: 0.8208 - val_loss: 0.4550 - val_acc: 0.8216\n",
      "Epoch 53/60\n",
      "57600/57600 [==============================] - 9s 156us/step - loss: 0.4473 - acc: 0.8159 - val_loss: 0.4717 - val_acc: 0.8159\n",
      "Epoch 54/60\n",
      "57600/57600 [==============================] - 9s 155us/step - loss: 0.4493 - acc: 0.8165 - val_loss: 0.4514 - val_acc: 0.8232\n",
      "Epoch 55/60\n",
      "57600/57600 [==============================] - 9s 154us/step - loss: 0.4467 - acc: 0.8176 - val_loss: 0.4756 - val_acc: 0.8153\n",
      "Epoch 56/60\n",
      "57600/57600 [==============================] - 9s 156us/step - loss: 0.4485 - acc: 0.8178 - val_loss: 0.4557 - val_acc: 0.8228\n",
      "Epoch 57/60\n",
      "57600/57600 [==============================] - 9s 154us/step - loss: 0.4452 - acc: 0.8196 - val_loss: 0.4627 - val_acc: 0.8176\n",
      "Epoch 58/60\n",
      "57600/57600 [==============================] - 9s 154us/step - loss: 0.4458 - acc: 0.8183 - val_loss: 0.4477 - val_acc: 0.8231\n",
      "Epoch 59/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57600/57600 [==============================] - 9s 151us/step - loss: 0.4471 - acc: 0.8187 - val_loss: 0.4675 - val_acc: 0.8177\n",
      "Epoch 60/60\n",
      "57600/57600 [==============================] - 9s 153us/step - loss: 0.4413 - acc: 0.8194 - val_loss: 0.4568 - val_acc: 0.8224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5e9cc9fbe0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 60\n",
    "\n",
    "model.fit(images, labels_onehot,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_split = 0.2,\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('xjbp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
