{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/share/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Activation, \\\n",
    "    Flatten, Lambda, LSTM, RepeatVector, TimeDistributed, Reshape, \\\n",
    "    Conv2D, MaxPooling2D, BatchNormalization, ConvLSTM2D, Bidirectional, Masking\n",
    "import keras.callbacks as Callbacks \n",
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import scale\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.util import random_noise\n",
    "from skimage.transform import rotate\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data keys: ['images', 'labels', 'observation_days']\n"
     ]
    }
   ],
   "source": [
    "data = h5py.File(\"data/data_sample.hdf5\", \"r\")\n",
    "print(\"data keys: \" + str(list(data.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: (sample, x_size, y_size, epoch) = (72000, 21, 21, 48)\n"
     ]
    }
   ],
   "source": [
    "images = data[\"images\"][:]\n",
    "print(\"image shape: (sample, x_size, y_size, epoch) = \" + str(images.shape))\n",
    "labels = data[\"labels\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(images, percent=0.25):\n",
    "    \n",
    "    size, timestep, _, _ = images.shape\n",
    "    sample_size = int(size * percent)\n",
    "    \n",
    "    np.random.seed(209)\n",
    "    # pick the sequence with replacement\n",
    "    sample_seq_indices = np.random.choice(np.arange(sample_size), sample_size)\n",
    "    # pick the timestep\n",
    "    sample_inseq_indices = np.random.choice(np.arange(timestep), sample_size)\n",
    "    # pick the aug mean\n",
    "    sample_aug_type = np.random.choice(np.arange(4), sample_size)\n",
    "    \n",
    "    for idx in range(sample_size):\n",
    "        i, j, k = sample_seq_indices[idx], \\\n",
    "            sample_inseq_indices[idx], sample_aug_type[idx]\n",
    "        if k == 0: # rotate\n",
    "            images[i, j] = rotate(images[i, j], 45)\n",
    "        elif k == 1: # random noise\n",
    "            images[i, j] = random_noise(images[i, j], seed=209)\n",
    "        elif k == 2: # horizontal flip\n",
    "            images[i, j] = images[i, j][:,::-1]\n",
    "        else: # vertical flip\n",
    "            images[i, j] = images[i, j][::-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_images(images):\n",
    "    t_images = np.transpose(images, (0,3,1,2))\n",
    "    rt_images = t_images.reshape(72000*48, 21, 21)\n",
    "    max_per_img = np.max(rt_images.reshape(-1, 21*21), axis=1, keepdims=1)\n",
    "    scaled_images = rt_images.reshape(-1, 21*21) / max_per_img\n",
    "    scaled_images = scaled_images.reshape(-1, 21, 21).reshape(-1, 48, 21, 21)\n",
    "    return scaled_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt2digit(labels):\n",
    "    dic = {'Asteroids':0, 'Constant':1, 'EmptyLigh':2, 'M33Cephei':3, 'RRLyrae':4, 'Supernova':5}\n",
    "    labels_digit = np.array([dic[i] for i in labels])\n",
    "    return labels_digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(images, labels):\n",
    "    scaled_img = scale_images(images)\n",
    "    preprocess_img(scaled_img)\n",
    "    x = np.expand_dims(scaled_img, len(scaled_img.shape))\n",
    "    y = to_categorical(txt2digit(labels))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = build_dataset(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(cnn_input_dim=21, cnn_output_dim=128, cnn_dropout=0.5,\n",
    "               rnn_hidden_dim=128, rnn_output_dim=64, num_classes=6, rnn_dropout=0.5, timestep=48):\n",
    "    \n",
    "    \n",
    "    intput_shape = (timestep, cnn_input_dim, cnn_input_dim, 1)\n",
    "    model = Sequential()\n",
    "    # CNN\n",
    "    model.add(TimeDistributed(Conv2D(32, (4,4), \\\n",
    "                     padding='same', activation='relu', kernel_initializer='uniform'), \\\n",
    "                              input_shape=intput_shape))\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(cnn_dropout))\n",
    "    \n",
    "    model.add(TimeDistributed(MaxPooling2D((3,3), strides=(1,1))))\n",
    "    model.add(TimeDistributed(Conv2D(64, (3,3), padding='same', activation='relu', kernel_initializer='uniform')))\n",
    "    \n",
    "    #model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(64, (3,3), padding='same', activation='relu', kernel_initializer='uniform')))\n",
    "    \n",
    "    #model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(TimeDistributed(MaxPooling2D((3,3), strides=(1,1))))\n",
    "    model.add(TimeDistributed(Conv2D(32, (3,3), padding='same', activation='relu', kernel_initializer='uniform')))\n",
    "    \n",
    "    #model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(32, (3,3), padding='same', activation='relu', kernel_initializer='uniform')))\n",
    "    \n",
    "    #model.add(BatchNormalization())\n",
    "#     model.add(Dropout(cnn_dropout))\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(32, (3,3), padding='same', activation='relu', kernel_initializer='uniform')))\n",
    "    #model.add(Dropout(cnn_dropout))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(TimeDistributed(MaxPooling2D((3,3), strides=(1,1))))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(TimeDistributed(Dense(128, activation='relu')))\n",
    "    \n",
    "    #model.add(BatchNormalization())\n",
    "#     model.add(Dropout(cnn_dropout))\n",
    "    \n",
    "    model.add(TimeDistributed(Dense(cnn_output_dim, activation='relu')))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(rnn_hidden_dim, dropout=rnn_dropout, return_sequences=True), \\\n",
    "                          input_shape=(timestep, cnn_output_dim)))\n",
    "    # repeat vector for timestep\n",
    "    #model.add(RepeatVector(timestep))\n",
    "    # decode\n",
    "    model.add(Bidirectional(LSTM(rnn_hidden_dim, dropout=rnn_dropout)))\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    #out = rnn(cat)\n",
    "    \n",
    "    return model#Model(inputs=iL, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model3(cnn_input_dim=21, cnn_output_dim=128, cnn_dropout=0.5,\n",
    "               rnn_hidden_dim=128, rnn_output_dim=64, num_classes=6, rnn_dropout=0.5, timestep=48,\n",
    "               bidir_mode='concat'):\n",
    "    \n",
    "    input_shape = (timestep, cnn_input_dim, cnn_input_dim, 1, )\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(TimeDistributed(Masking(), input_shape=input_shape, name='Masking'))\n",
    "    model.add(TimeDistributed(Conv2D(48, (4,4), \\\n",
    "                     padding='same', activation='relu', kernel_initializer='uniform'), \\\n",
    "                              input_shape=input_shape, name='Conv2D_1'))\n",
    "    model.add(TimeDistributed(MaxPooling2D((3,3), strides=(1,1)), name='MaxPooling2D_1'))\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(24, (3,3), padding='same', activation='relu', kernel_initializer='uniform'),\\\n",
    "                 name='Conv2D_2'))\n",
    "    model.add(TimeDistributed(MaxPooling2D((3,3), strides=(1,1)), name='MaxPooling2D_2'))\n",
    "\n",
    "    model.add(TimeDistributed(Conv2D(12, (3,3), padding='same', activation='relu', kernel_initializer='uniform'), \\\n",
    "                             name='Conv2D_3'))\n",
    "    model.add(TimeDistributed(MaxPooling2D((3,3), strides=(1,1)), name='MaxPooling2D_3'))\n",
    "    \n",
    "    model.add(TimeDistributed(Flatten(), name='Faltten'))\n",
    "\n",
    "    model.add(TimeDistributed(Dense(128, activation='relu'), name='Dense_128'))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(rnn_hidden_dim, dropout=rnn_dropout, return_sequences=True), \\\n",
    "                          input_shape=(timestep, cnn_output_dim), merge_mode=bidir_mode, name='Bi-directional_LSTM_1'))\n",
    "    model.add(Bidirectional(LSTM(rnn_hidden_dim, dropout=rnn_dropout), merge_mode=bidir_mode, name='Bi-directional_LSTM_2'))\n",
    "    model.add(Dense(6, activation='softmax', name='Output_Dense'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_model3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Masking (TimeDistributed)    (None, 48, 21, 21, 1)     0         \n",
      "_________________________________________________________________\n",
      "Conv2D_1 (TimeDistributed)   (None, 48, 21, 21, 48)    816       \n",
      "_________________________________________________________________\n",
      "MaxPooling2D_1 (TimeDistribu (None, 48, 19, 19, 48)    0         \n",
      "_________________________________________________________________\n",
      "Conv2D_2 (TimeDistributed)   (None, 48, 19, 19, 24)    10392     \n",
      "_________________________________________________________________\n",
      "MaxPooling2D_2 (TimeDistribu (None, 48, 17, 17, 24)    0         \n",
      "_________________________________________________________________\n",
      "Conv2D_3 (TimeDistributed)   (None, 48, 17, 17, 12)    2604      \n",
      "_________________________________________________________________\n",
      "MaxPooling2D_3 (TimeDistribu (None, 48, 15, 15, 12)    0         \n",
      "_________________________________________________________________\n",
      "Faltten (TimeDistributed)    (None, 48, 2700)          0         \n",
      "_________________________________________________________________\n",
      "Dense_128 (TimeDistributed)  (None, 48, 128)           345728    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 48, 128)           0         \n",
      "_________________________________________________________________\n",
      "Bi-directional_LSTM_1 (Bidir (None, 48, 256)           263168    \n",
      "_________________________________________________________________\n",
      "Bi-directional_LSTM_2 (Bidir (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "Output_Dense (Dense)         (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,018,490\n",
      "Trainable params: 1,018,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 80\n",
    "opt = keras.optimizers.Adam(lr=5*1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cpt = Callbacks.ModelCheckpoint(filepath='models/model3_#lstm=2_bi=concat_weights.{epoch:02d}-{val_loss:.2f}.hdf5', \n",
    "                      save_best_only=True, period=10)\n",
    "tensorboard = Callbacks.TensorBoard(log_dir='./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 1.7918 - acc: 0.1712 - val_loss: 1.7965 - val_acc: 0.1300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f27f97bb8d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x[:1000], y[:1000], batch_size=256, epochs=1,\n",
    "              validation_split=0.2, shuffle=False, callbacks=[cpt, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28800 samples, validate on 7200 samples\n",
      "Epoch 1/100\n",
      "28800/28800 [==============================] - 241s 8ms/step - loss: 1.5522 - acc: 0.3018 - val_loss: 1.5422 - val_acc: 0.3571\n",
      "Epoch 2/100\n",
      "28800/28800 [==============================] - 234s 8ms/step - loss: 1.2763 - acc: 0.3983 - val_loss: 1.0378 - val_acc: 0.4697\n",
      "Epoch 3/100\n",
      "28800/28800 [==============================] - 234s 8ms/step - loss: 1.0860 - acc: 0.4692 - val_loss: 0.9510 - val_acc: 0.5094\n",
      "Epoch 4/100\n",
      "28800/28800 [==============================] - 234s 8ms/step - loss: 0.9479 - acc: 0.5215 - val_loss: 0.8956 - val_acc: 0.5414\n",
      "Epoch 5/100\n",
      "28800/28800 [==============================] - 234s 8ms/step - loss: 0.8940 - acc: 0.5459 - val_loss: 0.8682 - val_acc: 0.5553\n",
      "Epoch 6/100\n",
      "28800/28800 [==============================] - 234s 8ms/step - loss: 0.8925 - acc: 0.5502 - val_loss: 0.8542 - val_acc: 0.5601\n",
      "Epoch 7/100\n",
      "28800/28800 [==============================] - 234s 8ms/step - loss: 0.8382 - acc: 0.5653 - val_loss: 0.8373 - val_acc: 0.5831\n",
      "Epoch 8/100\n",
      "28800/28800 [==============================] - 234s 8ms/step - loss: 0.8886 - acc: 0.5549 - val_loss: 0.9552 - val_acc: 0.5097\n",
      "Epoch 9/100\n",
      "28800/28800 [==============================] - 234s 8ms/step - loss: 1.2518 - acc: 0.4326 - val_loss: 0.8813 - val_acc: 0.5385\n",
      "Epoch 10/100\n",
      "28800/28800 [==============================] - 234s 8ms/step - loss: 0.8886 - acc: 0.5532 - val_loss: 0.8360 - val_acc: 0.5714\n",
      "Epoch 11/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.8500 - acc: 0.5644 - val_loss: 0.8521 - val_acc: 0.5406\n",
      "Epoch 12/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.8278 - acc: 0.5731 - val_loss: 0.8102 - val_acc: 0.5944\n",
      "Epoch 13/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.8269 - acc: 0.5797 - val_loss: 0.9676 - val_acc: 0.5569\n",
      "Epoch 14/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.9462 - acc: 0.5474 - val_loss: 0.8015 - val_acc: 0.5681\n",
      "Epoch 15/100\n",
      "28800/28800 [==============================] - 234s 8ms/step - loss: 0.8060 - acc: 0.5955 - val_loss: 0.7770 - val_acc: 0.6314\n",
      "Epoch 16/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.7784 - acc: 0.6143 - val_loss: 0.7346 - val_acc: 0.6529\n",
      "Epoch 17/100\n",
      "28800/28800 [==============================] - 234s 8ms/step - loss: 0.8067 - acc: 0.6025 - val_loss: 0.7315 - val_acc: 0.6565\n",
      "Epoch 18/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 1.4329 - acc: 0.3717 - val_loss: 1.0274 - val_acc: 0.5149\n",
      "Epoch 19/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.8697 - acc: 0.5821 - val_loss: 0.8407 - val_acc: 0.6029\n",
      "Epoch 20/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.8166 - acc: 0.6002 - val_loss: 0.7613 - val_acc: 0.6331\n",
      "Epoch 21/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.7690 - acc: 0.6254 - val_loss: 0.7511 - val_acc: 0.6350\n",
      "Epoch 22/100\n",
      "28800/28800 [==============================] - 234s 8ms/step - loss: 0.7571 - acc: 0.6308 - val_loss: 0.7346 - val_acc: 0.6385\n",
      "Epoch 23/100\n",
      "28800/28800 [==============================] - 234s 8ms/step - loss: 0.8715 - acc: 0.5934 - val_loss: 0.7296 - val_acc: 0.6443\n",
      "Epoch 24/100\n",
      "28800/28800 [==============================] - 234s 8ms/step - loss: 0.7498 - acc: 0.6375 - val_loss: 0.6947 - val_acc: 0.6637\n",
      "Epoch 25/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.7278 - acc: 0.6440 - val_loss: 0.7035 - val_acc: 0.6654\n",
      "Epoch 26/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.7311 - acc: 0.6448 - val_loss: 0.8608 - val_acc: 0.5956\n",
      "Epoch 27/100\n",
      "28800/28800 [==============================] - 234s 8ms/step - loss: 0.7290 - acc: 0.6495 - val_loss: 0.6876 - val_acc: 0.6781\n",
      "Epoch 28/100\n",
      "28800/28800 [==============================] - 234s 8ms/step - loss: 0.7197 - acc: 0.6548 - val_loss: 0.7100 - val_acc: 0.6640\n",
      "Epoch 29/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.7091 - acc: 0.6617 - val_loss: 0.6421 - val_acc: 0.6910\n",
      "Epoch 30/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.6739 - acc: 0.6764 - val_loss: 0.6526 - val_acc: 0.6744\n",
      "Epoch 31/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.6952 - acc: 0.6672 - val_loss: 0.6727 - val_acc: 0.6793\n",
      "Epoch 32/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.6650 - acc: 0.6798 - val_loss: 0.6509 - val_acc: 0.6867\n",
      "Epoch 33/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.6983 - acc: 0.6664 - val_loss: 0.7184 - val_acc: 0.6706\n",
      "Epoch 34/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.6738 - acc: 0.6825 - val_loss: 0.6964 - val_acc: 0.6856\n",
      "Epoch 35/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.6490 - acc: 0.6933 - val_loss: 0.6327 - val_acc: 0.6942\n",
      "Epoch 36/100\n",
      " 4000/28800 [===>..........................] - ETA: 3:05 - loss: 0.6415 - acc: 0.6905"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.6155 - acc: 0.7075 - val_loss: 0.6817 - val_acc: 0.6883\n",
      "Epoch 39/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.6228 - acc: 0.7068 - val_loss: 0.5999 - val_acc: 0.7204\n",
      "Epoch 40/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.6132 - acc: 0.7130 - val_loss: 0.6027 - val_acc: 0.7275\n",
      "Epoch 41/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.5971 - acc: 0.7219 - val_loss: 0.5885 - val_acc: 0.7372\n",
      "Epoch 42/100\n",
      "28800/28800 [==============================] - 232s 8ms/step - loss: 0.6036 - acc: 0.7183 - val_loss: 0.5659 - val_acc: 0.7360\n",
      "Epoch 43/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.5810 - acc: 0.7289 - val_loss: 0.5745 - val_acc: 0.7314\n",
      "Epoch 44/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.5752 - acc: 0.7325 - val_loss: 0.5707 - val_acc: 0.7406\n",
      "Epoch 45/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.5812 - acc: 0.7318 - val_loss: 0.5270 - val_acc: 0.7600\n",
      "Epoch 46/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.5919 - acc: 0.7275 - val_loss: 0.5678 - val_acc: 0.7406\n",
      "Epoch 47/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.5723 - acc: 0.7382 - val_loss: 0.5560 - val_acc: 0.7488\n",
      "Epoch 48/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.5398 - acc: 0.7548 - val_loss: 0.5363 - val_acc: 0.7558\n",
      "Epoch 49/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.5383 - acc: 0.7560 - val_loss: 0.5126 - val_acc: 0.7707\n",
      "Epoch 50/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.5416 - acc: 0.7568 - val_loss: 0.5027 - val_acc: 0.7701\n",
      "Epoch 51/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.5171 - acc: 0.7668 - val_loss: 0.5081 - val_acc: 0.7810\n",
      "Epoch 52/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.5149 - acc: 0.7702 - val_loss: 0.5570 - val_acc: 0.7693\n",
      "Epoch 53/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.5019 - acc: 0.7752 - val_loss: 1.1428 - val_acc: 0.6449\n",
      "Epoch 54/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.5339 - acc: 0.7631 - val_loss: 0.5143 - val_acc: 0.7801\n",
      "Epoch 55/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.4957 - acc: 0.7793 - val_loss: 0.4910 - val_acc: 0.7850\n",
      "Epoch 56/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.4894 - acc: 0.7828 - val_loss: 0.4900 - val_acc: 0.7860\n",
      "Epoch 57/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.4708 - acc: 0.7890 - val_loss: 0.4584 - val_acc: 0.8050\n",
      "Epoch 58/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.5109 - acc: 0.7764 - val_loss: 0.4604 - val_acc: 0.8014\n",
      "Epoch 59/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.4771 - acc: 0.7908 - val_loss: 0.4593 - val_acc: 0.7985\n",
      "Epoch 60/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.4819 - acc: 0.7868 - val_loss: 0.4515 - val_acc: 0.8053\n",
      "Epoch 61/100\n",
      "28800/28800 [==============================] - 232s 8ms/step - loss: 0.4765 - acc: 0.7916 - val_loss: 0.4392 - val_acc: 0.8103\n",
      "Epoch 62/100\n",
      "28800/28800 [==============================] - 232s 8ms/step - loss: 0.4852 - acc: 0.7880 - val_loss: 0.4895 - val_acc: 0.7994\n",
      "Epoch 63/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.4594 - acc: 0.7977 - val_loss: 0.4774 - val_acc: 0.8060\n",
      "Epoch 64/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.4361 - acc: 0.8075 - val_loss: 0.4128 - val_acc: 0.8244\n",
      "Epoch 65/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.4334 - acc: 0.8096 - val_loss: 0.3828 - val_acc: 0.8338\n",
      "Epoch 66/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.4403 - acc: 0.8110 - val_loss: 0.4163 - val_acc: 0.8208\n",
      "Epoch 67/100\n",
      "28800/28800 [==============================] - 232s 8ms/step - loss: 0.4206 - acc: 0.8174 - val_loss: 0.4137 - val_acc: 0.8278\n",
      "Epoch 68/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.4162 - acc: 0.8198 - val_loss: 0.4303 - val_acc: 0.8222\n",
      "Epoch 69/100\n",
      "28800/28800 [==============================] - 232s 8ms/step - loss: 0.4134 - acc: 0.8205 - val_loss: 0.3989 - val_acc: 0.8346\n",
      "Epoch 70/100\n",
      "28800/28800 [==============================] - 232s 8ms/step - loss: 0.4087 - acc: 0.8233 - val_loss: 0.4247 - val_acc: 0.8254\n",
      "Epoch 71/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.4083 - acc: 0.8250 - val_loss: 0.4052 - val_acc: 0.8340\n",
      "Epoch 72/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.4075 - acc: 0.8248 - val_loss: 0.3698 - val_acc: 0.8431\n",
      "Epoch 73/100\n",
      "28800/28800 [==============================] - 232s 8ms/step - loss: 0.4046 - acc: 0.8260 - val_loss: 0.4241 - val_acc: 0.8250\n",
      "Epoch 74/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.4058 - acc: 0.8286 - val_loss: 0.3894 - val_acc: 0.8388\n",
      "Epoch 75/100\n",
      "28800/28800 [==============================] - 232s 8ms/step - loss: 0.3968 - acc: 0.8312 - val_loss: 0.3735 - val_acc: 0.8451\n",
      "Epoch 76/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.3804 - acc: 0.8387 - val_loss: 0.3630 - val_acc: 0.8486\n",
      "Epoch 77/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.3775 - acc: 0.8398 - val_loss: 0.3611 - val_acc: 0.8481\n",
      "Epoch 78/100\n",
      "28800/28800 [==============================] - 232s 8ms/step - loss: 0.3766 - acc: 0.8414 - val_loss: 0.3584 - val_acc: 0.8526\n",
      "Epoch 79/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.3737 - acc: 0.8412 - val_loss: 0.3644 - val_acc: 0.8492\n",
      "Epoch 80/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.3712 - acc: 0.8424 - val_loss: 0.3699 - val_acc: 0.8519\n",
      "Epoch 81/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.4127 - acc: 0.8285 - val_loss: 0.3657 - val_acc: 0.8538\n",
      "Epoch 82/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.3567 - acc: 0.8501 - val_loss: 0.3340 - val_acc: 0.8622\n",
      "Epoch 83/100\n",
      "28800/28800 [==============================] - 232s 8ms/step - loss: 0.3850 - acc: 0.8375 - val_loss: 0.3314 - val_acc: 0.8622\n",
      "Epoch 84/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.3534 - acc: 0.8515 - val_loss: 0.3479 - val_acc: 0.8606\n",
      "Epoch 85/100\n",
      "28800/28800 [==============================] - 232s 8ms/step - loss: 0.3702 - acc: 0.8440 - val_loss: 0.3714 - val_acc: 0.8511\n",
      "Epoch 86/100\n",
      "28800/28800 [==============================] - 232s 8ms/step - loss: 0.3557 - acc: 0.8517 - val_loss: 0.3739 - val_acc: 0.8503\n",
      "Epoch 87/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.3527 - acc: 0.8538 - val_loss: 0.4057 - val_acc: 0.8454\n",
      "Epoch 88/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.3452 - acc: 0.8559 - val_loss: 0.3187 - val_acc: 0.8722\n",
      "Epoch 89/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.3843 - acc: 0.8381 - val_loss: 0.3703 - val_acc: 0.8594\n",
      "Epoch 90/100\n",
      "28800/28800 [==============================] - 232s 8ms/step - loss: 0.3445 - acc: 0.8557 - val_loss: 0.3121 - val_acc: 0.8736\n",
      "Epoch 91/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.3344 - acc: 0.8593 - val_loss: 0.3364 - val_acc: 0.8692\n",
      "Epoch 92/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.3445 - acc: 0.8579 - val_loss: 0.3113 - val_acc: 0.8753\n",
      "Epoch 93/100\n",
      "28800/28800 [==============================] - 232s 8ms/step - loss: 0.3352 - acc: 0.8600 - val_loss: 0.3048 - val_acc: 0.8796\n",
      "Epoch 94/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.3266 - acc: 0.8652 - val_loss: 0.3698 - val_acc: 0.8582\n",
      "Epoch 95/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.3334 - acc: 0.8631 - val_loss: 0.3486 - val_acc: 0.8703\n",
      "Epoch 96/100\n",
      "28800/28800 [==============================] - 232s 8ms/step - loss: 0.3310 - acc: 0.8611 - val_loss: 0.3118 - val_acc: 0.8758\n",
      "Epoch 97/100\n",
      "28800/28800 [==============================] - 233s 8ms/step - loss: 0.3304 - acc: 0.8648 - val_loss: 0.3321 - val_acc: 0.8733\n",
      "Epoch 98/100\n",
      "28800/28800 [==============================] - 232s 8ms/step - loss: 0.3209 - acc: 0.8689 - val_loss: 0.3036 - val_acc: 0.8812\n",
      "Epoch 99/100\n",
      "28800/28800 [==============================] - 232s 8ms/step - loss: 0.3153 - acc: 0.8702 - val_loss: 0.3300 - val_acc: 0.8761\n",
      "Epoch 100/100\n",
      "28800/28800 [==============================] - 232s 8ms/step - loss: 0.3130 - acc: 0.8720 - val_loss: 0.3266 - val_acc: 0.8733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8e47b13cc0>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x[::2], y[::2], batch_size=80, epochs=100,\n",
    "              validation_split=0.2, shuffle=True, callbacks=[cpt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = Callbacks.TensorBoard(log_dir='./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 288000 samples, validate on 72000 samples\n",
      "Epoch 1/100\n",
      "   776/288000 [..............................] - ETA: 15:38:51 - loss: 1.6114 - acc: 0.3918"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-982b0d83ce5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model4.fit(stateful_x, stateful_y, batch_size=1, epochs=100,\n\u001b[0;32m----> 2\u001b[0;31m               validation_split=0.2, shuffle=False, callbacks=[cpt, ResetStatesCallback()])\n\u001b[0m",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model3.fit(stateful_x, stateful_y, batch_size=1, epochs=100,\n",
    "              validation_split=0.2, shuffle=False, callbacks=[cpt, ResetStatesCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
