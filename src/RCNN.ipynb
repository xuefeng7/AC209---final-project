{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Activation, \\\n",
    "    Flatten, Lambda, LSTM, RepeatVector, TimeDistributed, Reshape\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # models\n",
    "# from keras.applications.inception_v3 import InceptionV3\n",
    "# from keras.applications.vgg16 import VGG16\n",
    "# from keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data keys: ['images', 'labels', 'observation_days']\n"
     ]
    }
   ],
   "source": [
    "data = h5py.File(\"../dataset/data_sample.hdf5\", \"r\")\n",
    "print(\"data keys: \" + str(list(data.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: (sample, x_size, y_size, epoch) = (72000, 21, 21, 48)\n"
     ]
    }
   ],
   "source": [
    "images = data[\"images\"][:]\n",
    "print(\"image shape: (sample, x_size, y_size, epoch) = \" + str(images.shape))\n",
    "labels = data[\"labels\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(labels):\n",
    "    dic = {'Asteroids':0, 'Constant':1, 'EmptyLigh':2, 'M33Cephei':3, 'RRLyrae':4, 'Supernova':5}\n",
    "    labels_digit = np.array([dic[i] for i in labels])\n",
    "    labels_digit = np.repeat(labels_digit, 48)\n",
    "    labels_onehot = np.zeros((labels_digit.shape[0], 6))\n",
    "    labels_onehot[np.arange(labels_digit.shape[0]), labels_digit] = 1\n",
    "    return labels_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_dataset(images, labels):\n",
    "    \n",
    "    train_indices = np.random.choice(np.arange(images.shape[0]), int( 0.7 * images.shape[0]))\n",
    "    val_indices = list(set(np.arange(images.shape[0])) - set(train_indices))\n",
    "    \n",
    "    x = np.transpose(images, (0, 3, 1, 2))\n",
    "    x = np.expand_dims(x, len(x.shape))\n",
    "    y = one_hot_encode(labels).reshape(-1, 48, 6)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = build_dataset(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## shuffle and row selection are\n",
    "# very slow\n",
    "# x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.3)\n",
    "## maybe flatten -> select -> reshape back ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_model(cnn_input_dim=21, cnn_output_dim=128, cnn_dropout=0.5,\n",
    "               rnn_hidden_dim=128, rnn_output_dim=64, num_classes=6, rnn_dropout=0.5, timestep=48):\n",
    "    \n",
    "    intput_shape = (timestep, cnn_input_dim, cnn_input_dim, 1)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # CNN\n",
    "    model.add(TimeDistributed(Conv2D(32, (4,4), \\\n",
    "                     padding='same', activation='relu', kernel_initializer='uniform'), input_shape=intput_shape))\n",
    "    model.add(TimeDistributed(MaxPooling2D((3,3), strides=(1,1))))\n",
    "    model.add(TimeDistributed(Conv2D(64, (3,3), padding='same', activation='relu', kernel_initializer='uniform')))\n",
    "    model.add(TimeDistributed(Conv2D(64, (3,3), padding='same', activation='relu', kernel_initializer='uniform')))\n",
    "    model.add(TimeDistributed(MaxPooling2D((3,3), strides=(1,1))))\n",
    "    model.add(TimeDistributed(Conv2D(32, (3,3), padding='same', activation='relu', kernel_initializer='uniform')))\n",
    "    model.add(TimeDistributed(Conv2D(32, (3,3), padding='same', activation='relu', kernel_initializer='uniform')))\n",
    "    model.add(TimeDistributed(Conv2D(32, (3,3), padding='same', activation='relu', kernel_initializer='uniform')))\n",
    "    model.add(TimeDistributed(MaxPooling2D((3,3), strides=(1,1))))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "    model.add(Dropout(cnn_dropout))\n",
    "    model.add(TimeDistributed(Dense(cnn_output_dim, activation='relu')))\n",
    "    \n",
    "    # RNN\n",
    "    # rnn_input_dim = cnn_output_dim\n",
    "    # encode\n",
    "    model.add(LSTM(rnn_hidden_dim, input_shape=(timestep, cnn_output_dim)))\n",
    "    # repeat vector for timestep\n",
    "    model.add(RepeatVector(timestep))\n",
    "    # decode\n",
    "    # TODO: do some research on stacked LSTM\n",
    "    model.add(LSTM(rnn_hidden_dim, dropout=rnn_dropout, return_sequences=True))\n",
    "    # add dense\n",
    "    model.add(TimeDistributed(Dense(num_classes, activation='softmax')))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 20\n",
    "\n",
    "model.fit(x[:500], y[:500],\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x[600:700], y[600:700]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(trainset, testset, cnn, rnn, batch_size=128, num_epoch=10, lr=0.0001, \n",
    "          print_every=100, early_stop=True):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
