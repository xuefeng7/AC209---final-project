{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Activation, \\\n",
    "    Flatten, Lambda, LSTM, RepeatVector, TimeDistributed, Reshape, \\\n",
    "    Conv2D, MaxPooling2D, BatchNormalization, ConvLSTM2D, Bidirectional\n",
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # models\n",
    "# from keras.applications.inception_v3 import InceptionV3\n",
    "# from keras.applications.vgg16 import VGG16\n",
    "# from keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data keys: ['images', 'labels', 'observation_days']\n"
     ]
    }
   ],
   "source": [
    "data = h5py.File(\"../dataset/data_sample.hdf5\", \"r\")\n",
    "print(\"data keys: \" + str(list(data.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: (sample, x_size, y_size, epoch) = (72000, 21, 21, 48)\n"
     ]
    }
   ],
   "source": [
    "images = data[\"images\"][:]\n",
    "print(\"image shape: (sample, x_size, y_size, epoch) = \" + str(images.shape))\n",
    "labels = data[\"labels\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_images(images):\n",
    "    t_images = np.transpose(images, (0,3,1,2))\n",
    "    rt_images = timages.reshape(72000*48, 21, 21)\n",
    "    max_per_img = np.max(rt_images.reshape(-1, 21*21), axis=1, keepdims=1)\n",
    "    scaled_images = rt_images.reshape(-1, 21*21) / max_per_img\n",
    "    scaled_images = scaled_images.reshape(-1, 21, 21).reshape(-1, 48, 21, 21)\n",
    "    return scaled_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def txt2digit(labels):\n",
    "    dic = {'Asteroids':0, 'Constant':1, 'EmptyLigh':2, 'M33Cephei':3, 'RRLyrae':4, 'Supernova':5}\n",
    "    labels_digit = np.array([dic[i] for i in labels])\n",
    "    return labels_digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_dataset(images, labels, seq2seq=False):\n",
    "    \n",
    "    train_indices = np.random.choice(np.arange(images.shape[0]), int( 0.7 * images.shape[0]))\n",
    "    val_indices = list(set(np.arange(images.shape[0])) - set(train_indices))\n",
    "    \n",
    "    x = np.transpose(images, (0, 3, 1, 2))\n",
    "    x = np.expand_dims(x, len(x.shape))\n",
    "    y = to_categorical(txt2digit(labels))\n",
    "    \n",
    "    if seq2seq:\n",
    "        y = np.repeat(y, 48).reshape(-1, 48, 6)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = build_dataset(scale_images(), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## shuffle and row selection are\n",
    "# very slow\n",
    "# x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.3)\n",
    "## maybe flatten -> select -> reshape back ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_model(cnn_input_dim=21, cnn_output_dim=128, cnn_dropout=0.5,\n",
    "               rnn_hidden_dim=128, rnn_output_dim=64, num_classes=6, rnn_dropout=0.5, timestep=48):\n",
    "    \n",
    "    intput_shape = (timestep, cnn_input_dim, cnn_input_dim, 1)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # CNN\n",
    "    model.add(TimeDistributed(Conv2D(32, (4,4), \\\n",
    "                     padding='same', activation='relu', kernel_initializer='uniform'), input_shape=intput_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(TimeDistributed(MaxPooling2D((3,3), strides=(1,1))))\n",
    "    model.add(Dropout(cnn_dropout))\n",
    "    model.add(TimeDistributed(Conv2D(64, (3,3), padding='same', activation='relu', kernel_initializer='uniform')))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(TimeDistributed(Conv2D(64, (3,3), padding='same', activation='relu', kernel_initializer='uniform')))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(TimeDistributed(MaxPooling2D((3,3), strides=(1,1))))\n",
    "    model.add(TimeDistributed(Conv2D(32, (3,3), padding='same', activation='relu', kernel_initializer='uniform')))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(TimeDistributed(Conv2D(32, (3,3), padding='same', activation='relu', kernel_initializer='uniform')))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(TimeDistributed(Conv2D(32, (3,3), padding='same', activation='relu', kernel_initializer='uniform')))\n",
    "    model.add(Dropout(cnn_dropout))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(TimeDistributed(MaxPooling2D((3,3), strides=(1,1))))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(cnn_dropout))\n",
    "    model.add(TimeDistributed(Dense(cnn_output_dim, activation='relu')))\n",
    "    \n",
    "    # RNN\n",
    "    # rnn_input_dim = cnn_output_dim\n",
    "    # encode\n",
    "    model.add(LSTM(rnn_hidden_dim, input_shape=(timestep, cnn_output_dim), dropout=rnn_dropout))\n",
    "    # repeat vector for timestep\n",
    "    #model.add(RepeatVector(timestep))\n",
    "    # decode\n",
    "    # TODO: do some research on stacked LSTM\n",
    "    #model.add(LSTM(rnn_hidden_dim, dropout=rnn_dropout, return_sequences=True))\n",
    "    # add dense\n",
    "    # model.add(TimeDistributed(Dense(num_classes, activation='softmax')))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_40 (TimeDis (None, 48, 21, 21, 32)    544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 21, 21, 32)    128       \n",
      "_________________________________________________________________\n",
      "time_distributed_41 (TimeDis (None, 48, 19, 19, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_42 (TimeDis (None, 48, 19, 19, 64)    18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 19, 19, 64)    256       \n",
      "_________________________________________________________________\n",
      "time_distributed_43 (TimeDis (None, 48, 19, 19, 64)    36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 48, 19, 19, 64)    256       \n",
      "_________________________________________________________________\n",
      "time_distributed_44 (TimeDis (None, 48, 17, 17, 64)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_45 (TimeDis (None, 48, 17, 17, 32)    18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 48, 17, 17, 32)    128       \n",
      "_________________________________________________________________\n",
      "time_distributed_46 (TimeDis (None, 48, 17, 17, 32)    9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 48, 17, 17, 32)    128       \n",
      "_________________________________________________________________\n",
      "time_distributed_47 (TimeDis (None, 48, 17, 17, 32)    9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 48, 17, 17, 32)    128       \n",
      "_________________________________________________________________\n",
      "time_distributed_48 (TimeDis (None, 48, 15, 15, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_49 (TimeDis (None, 48, 7200)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_50 (TimeDis (None, 48, 256)           1843456   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 48, 256)           1024      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 48, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_51 (TimeDis (None, 48, 128)           32896     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 2,103,686\n",
      "Trainable params: 2,102,662\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_model2():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(ConvLSTM2D(64, (4, 4), input_shape=(48, 21, 21, 1,), \\\n",
    "                     return_sequences=1, activation='relu', recurrent_dropout=0.4, data_format='channels_last'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(ConvLSTM2D(32, (3, 3), activation='relu', recurrent_dropout=0.4, data_format='channels_last'))\n",
    "    model.add(Flatten())\n",
    "    #model.add(Dropout(0.2))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_model3(cnn_input_dim=21, cnn_output_dim=128, cnn_dropout=0.5,\n",
    "               rnn_hidden_dim=128, rnn_output_dim=64, num_classes=6, rnn_dropout=0.5, timestep=48,\n",
    "               bidir_mode='concat'):\n",
    "    \n",
    "    input_shape = (timestep, cnn_input_dim, cnn_input_dim, 1, )\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(48, (4,4), \\\n",
    "                     padding='same', activation='relu', kernel_initializer='uniform'), input_shape=input_shape))\n",
    "    model.add(TimeDistributed(MaxPooling2D((3,3), strides=(1,1))))\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(24, (3,3), padding='same', activation='relu', kernel_initializer='uniform')))\n",
    "    model.add(TimeDistributed(MaxPooling2D((3,3), strides=(1,1))))\n",
    "\n",
    "    model.add(TimeDistributed(Conv2D(12, (3,3), padding='same', activation='relu', kernel_initializer='uniform')))\n",
    "    model.add(TimeDistributed(MaxPooling2D((3,3), strides=(1,1))))\n",
    "    \n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "    model.add(TimeDistributed(Dense(128, activation='relu')))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(rnn_hidden_dim, dropout=rnn_dropout, return_sequences=True), \\\n",
    "                          input_shape=(timestep, cnn_output_dim), merge_mode=bidir_mode))\n",
    "    model.add(Bidirectional(LSTM(rnn_hidden_dim, dropout=rnn_dropout), merge_mode=bidir_mode))\n",
    "    \n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(lr=5*1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = init_model2()\n",
    "model2.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3 = init_model3(bidir_mode='ave')\n",
    "model3.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28800 samples, validate on 7200 samples\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "batch_size = 80\n",
    "epochs = 100\n",
    "model2.fit(x[::2], y[::2],\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_split=0.2,\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
