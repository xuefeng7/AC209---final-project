{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/share/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Activation, \\\n",
    "    Flatten, Lambda, LSTM, RepeatVector, TimeDistributed, Reshape, \\\n",
    "    Conv2D, MaxPooling2D, BatchNormalization, ConvLSTM2D, Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = h5py.File(\"data_sample.hdf5\", \"r\")\n",
    "images = data[\"images\"][:]\n",
    "labels = data[\"labels\"][:]\n",
    "\n",
    "def scale_images(images):\n",
    "    t_images = np.transpose(images, (0,3,1,2))\n",
    "    rt_images = t_images.reshape(72000*48, 21, 21)\n",
    "    max_per_img = np.max(rt_images.reshape(-1, 21*21), axis=1, keepdims=1)\n",
    "    scaled_images = rt_images.reshape(-1, 21*21) / max_per_img\n",
    "    scaled_images = scaled_images.reshape(-1, 21, 21).reshape(-1, 48, 21, 21)\n",
    "    return scaled_images\n",
    "\n",
    "def txt2digit(labels):\n",
    "    dic = {'Asteroids':0, 'Constant':1, 'EmptyLigh':2, 'M33Cephei':3, 'RRLyrae':4, 'Supernova':5}\n",
    "    labels_digit = np.array([dic[i] for i in labels])\n",
    "    return labels_digit\n",
    "\n",
    "\n",
    "def build_dataset(images, labels, seq2seq=False):\n",
    "    \n",
    "    train_indices = np.random.choice(np.arange(images.shape[0]), int( 0.7 * images.shape[0]))\n",
    "    val_indices = list(set(np.arange(images.shape[0])) - set(train_indices))\n",
    "    \n",
    "    x = images\n",
    "    x = np.expand_dims(x, len(x.shape))\n",
    "    y = to_categorical(txt2digit(labels))\n",
    "    \n",
    "    if seq2seq:\n",
    "        y = np.repeat(y, 48).reshape(-1, 48, 6)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "x, y = build_dataset(scale_images(images), labels)\n",
    "x = x.reshape(x.shape[:-1]).transpose([0,2,3,1])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=209, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_cnn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(48, (4,4), input_shape=(21,21,48), padding='same', activation='relu', kernel_initializer='uniform'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling2D((3,3), strides=(1,1)))\n",
    "    \n",
    "    model.add(Conv2D(24, (3,3), padding='same', activation='relu', kernel_initializer='uniform'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling2D((3,3), strides=(1,1)))\n",
    "\n",
    "    model.add(Conv2D(12, (3,3), padding='same', activation='relu', kernel_initializer='uniform'))\n",
    "    model.add(MaxPooling2D((3,3), strides=(1,1)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "#     model.add(Dense(256, activation='relu'))\n",
    "#     model.add(Dropout(0.25))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 21, 21, 48)        36912     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 19, 19, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 19, 19, 24)        10392     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 17, 17, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 17, 17, 12)        2604      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 15, 15, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2700)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               345728    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 396,410\n",
      "Trainable params: 396,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = init_cnn()\n",
    "print(model.summary())\n",
    "adam = keras.optimizers.Adam(lr=0.0001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57600 samples, validate on 14400 samples\n",
      "Epoch 1/200\n",
      "57600/57600 [==============================] - 15s 252us/step - loss: 1.3449 - acc: 0.3963 - val_loss: 1.1446 - val_acc: 0.4044\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.14457, saving model to saved_models/cnn.hdf5\n",
      "Epoch 2/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 1.0513 - acc: 0.4821 - val_loss: 1.1330 - val_acc: 0.4614\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.14457 to 1.13301, saving model to saved_models/cnn.hdf5\n",
      "Epoch 3/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.9958 - acc: 0.4958 - val_loss: 0.9972 - val_acc: 0.5181\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.13301 to 0.99716, saving model to saved_models/cnn.hdf5\n",
      "Epoch 4/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.9687 - acc: 0.5063 - val_loss: 0.9290 - val_acc: 0.5125\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.99716 to 0.92896, saving model to saved_models/cnn.hdf5\n",
      "Epoch 5/200\n",
      "57600/57600 [==============================] - 14s 247us/step - loss: 0.9481 - acc: 0.5169 - val_loss: 0.9489 - val_acc: 0.5226\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.9359 - acc: 0.5242 - val_loss: 0.8984 - val_acc: 0.5416\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.92896 to 0.89839, saving model to saved_models/cnn.hdf5\n",
      "Epoch 7/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.9215 - acc: 0.5278 - val_loss: 0.9020 - val_acc: 0.5294\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.8978 - acc: 0.5410 - val_loss: 0.8860 - val_acc: 0.5459\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.89839 to 0.88599, saving model to saved_models/cnn.hdf5\n",
      "Epoch 9/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.8815 - acc: 0.5463 - val_loss: 0.8891 - val_acc: 0.5481\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.8996 - acc: 0.5417 - val_loss: 0.8861 - val_acc: 0.5501\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.8635 - acc: 0.5503 - val_loss: 0.8881 - val_acc: 0.5477\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.8519 - acc: 0.5604 - val_loss: 0.8215 - val_acc: 0.6008\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.88599 to 0.82148, saving model to saved_models/cnn.hdf5\n",
      "Epoch 13/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.8761 - acc: 0.5540 - val_loss: 0.8337 - val_acc: 0.5408\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.8426 - acc: 0.5671 - val_loss: 0.8180 - val_acc: 0.6224\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.82148 to 0.81797, saving model to saved_models/cnn.hdf5\n",
      "Epoch 15/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.8387 - acc: 0.5756 - val_loss: 0.8022 - val_acc: 0.5999\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.81797 to 0.80219, saving model to saved_models/cnn.hdf5\n",
      "Epoch 16/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.8333 - acc: 0.5764 - val_loss: 0.8070 - val_acc: 0.6043\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.8203 - acc: 0.5876 - val_loss: 0.8082 - val_acc: 0.6048\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.8183 - acc: 0.5905 - val_loss: 0.7862 - val_acc: 0.6039\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.80219 to 0.78618, saving model to saved_models/cnn.hdf5\n",
      "Epoch 19/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.8117 - acc: 0.5949 - val_loss: 0.7941 - val_acc: 0.5990\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.7959 - acc: 0.6058 - val_loss: 0.8163 - val_acc: 0.5502\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.7807 - acc: 0.6175 - val_loss: 0.7790 - val_acc: 0.6185\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.78618 to 0.77899, saving model to saved_models/cnn.hdf5\n",
      "Epoch 22/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.7769 - acc: 0.6197 - val_loss: 0.7852 - val_acc: 0.6087\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.7536 - acc: 0.6321 - val_loss: 0.7289 - val_acc: 0.6334\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.77899 to 0.72890, saving model to saved_models/cnn.hdf5\n",
      "Epoch 24/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.7486 - acc: 0.6370 - val_loss: 0.7379 - val_acc: 0.6445\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.7438 - acc: 0.6412 - val_loss: 0.7364 - val_acc: 0.6451\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 26/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.7324 - acc: 0.6491 - val_loss: 0.6840 - val_acc: 0.6711\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.72890 to 0.68402, saving model to saved_models/cnn.hdf5\n",
      "Epoch 27/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.7214 - acc: 0.6558 - val_loss: 0.7117 - val_acc: 0.6594\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 28/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.7332 - acc: 0.6504 - val_loss: 0.7545 - val_acc: 0.6193\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.7058 - acc: 0.6648 - val_loss: 0.6651 - val_acc: 0.6863\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.68402 to 0.66508, saving model to saved_models/cnn.hdf5\n",
      "Epoch 30/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.6898 - acc: 0.6713 - val_loss: 0.6753 - val_acc: 0.6812\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 31/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.7028 - acc: 0.6682 - val_loss: 0.8255 - val_acc: 0.6190\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "Epoch 32/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.6824 - acc: 0.6773 - val_loss: 0.7066 - val_acc: 0.6706\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "Epoch 33/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.6710 - acc: 0.6822 - val_loss: 0.6940 - val_acc: 0.6777\n",
      "\n",
      "Epoch 00033: val_loss did not improve\n",
      "Epoch 34/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.6724 - acc: 0.6838 - val_loss: 0.6340 - val_acc: 0.6998\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.66508 to 0.63402, saving model to saved_models/cnn.hdf5\n",
      "Epoch 35/200\n",
      "57600/57600 [==============================] - 14s 247us/step - loss: 0.6742 - acc: 0.6824 - val_loss: 0.6523 - val_acc: 0.6928\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "Epoch 36/200\n",
      "57600/57600 [==============================] - 14s 249us/step - loss: 0.6613 - acc: 0.6885 - val_loss: 0.6531 - val_acc: 0.6918\n",
      "\n",
      "Epoch 00036: val_loss did not improve\n",
      "Epoch 37/200\n",
      "57600/57600 [==============================] - 14s 249us/step - loss: 0.6614 - acc: 0.6898 - val_loss: 0.6212 - val_acc: 0.7001\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.63402 to 0.62119, saving model to saved_models/cnn.hdf5\n",
      "Epoch 38/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.6472 - acc: 0.6953 - val_loss: 0.6213 - val_acc: 0.7060\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "Epoch 39/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.6468 - acc: 0.6979 - val_loss: 0.6536 - val_acc: 0.6942\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "Epoch 40/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.6447 - acc: 0.6977 - val_loss: 0.6550 - val_acc: 0.6977\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "Epoch 41/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.6401 - acc: 0.7023 - val_loss: 0.6277 - val_acc: 0.7067\n",
      "\n",
      "Epoch 00041: val_loss did not improve\n",
      "Epoch 42/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.6291 - acc: 0.7055 - val_loss: 0.6507 - val_acc: 0.6960\n",
      "\n",
      "Epoch 00042: val_loss did not improve\n",
      "Epoch 43/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.6270 - acc: 0.7060 - val_loss: 0.6166 - val_acc: 0.7127\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.62119 to 0.61664, saving model to saved_models/cnn.hdf5\n",
      "Epoch 44/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.6288 - acc: 0.7065 - val_loss: 0.6369 - val_acc: 0.7009\n",
      "\n",
      "Epoch 00044: val_loss did not improve\n",
      "Epoch 45/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.6179 - acc: 0.7108 - val_loss: 0.6039 - val_acc: 0.7167\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.61664 to 0.60395, saving model to saved_models/cnn.hdf5\n",
      "Epoch 46/200\n",
      "57600/57600 [==============================] - 14s 243us/step - loss: 0.6162 - acc: 0.7124 - val_loss: 0.6117 - val_acc: 0.7169\n",
      "\n",
      "Epoch 00046: val_loss did not improve\n",
      "Epoch 47/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.6101 - acc: 0.7149 - val_loss: 0.6296 - val_acc: 0.7043\n",
      "\n",
      "Epoch 00047: val_loss did not improve\n",
      "Epoch 48/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.6071 - acc: 0.7179 - val_loss: 0.5948 - val_acc: 0.7215\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.60395 to 0.59479, saving model to saved_models/cnn.hdf5\n",
      "Epoch 49/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.6007 - acc: 0.7209 - val_loss: 0.5870 - val_acc: 0.7251\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.59479 to 0.58699, saving model to saved_models/cnn.hdf5\n",
      "Epoch 50/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.6047 - acc: 0.7196 - val_loss: 0.6268 - val_acc: 0.7074\n",
      "\n",
      "Epoch 00050: val_loss did not improve\n",
      "Epoch 51/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.6044 - acc: 0.7219 - val_loss: 0.5891 - val_acc: 0.7256\n",
      "\n",
      "Epoch 00051: val_loss did not improve\n",
      "Epoch 52/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.5905 - acc: 0.7273 - val_loss: 0.5773 - val_acc: 0.7275\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.58699 to 0.57729, saving model to saved_models/cnn.hdf5\n",
      "Epoch 53/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.5847 - acc: 0.7272 - val_loss: 0.5683 - val_acc: 0.7348\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.57729 to 0.56835, saving model to saved_models/cnn.hdf5\n",
      "Epoch 54/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.5918 - acc: 0.7265 - val_loss: 0.5818 - val_acc: 0.7317\n",
      "\n",
      "Epoch 00054: val_loss did not improve\n",
      "Epoch 55/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.5835 - acc: 0.7287 - val_loss: 0.5614 - val_acc: 0.7392\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.56835 to 0.56136, saving model to saved_models/cnn.hdf5\n",
      "Epoch 56/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.5771 - acc: 0.7334 - val_loss: 0.5717 - val_acc: 0.7380\n",
      "\n",
      "Epoch 00056: val_loss did not improve\n",
      "Epoch 57/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.5685 - acc: 0.7361 - val_loss: 0.5446 - val_acc: 0.7444\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.56136 to 0.54463, saving model to saved_models/cnn.hdf5\n",
      "Epoch 58/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.5626 - acc: 0.7397 - val_loss: 0.5546 - val_acc: 0.7419\n",
      "\n",
      "Epoch 00058: val_loss did not improve\n",
      "Epoch 59/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.5721 - acc: 0.7362 - val_loss: 0.5673 - val_acc: 0.7372\n",
      "\n",
      "Epoch 00059: val_loss did not improve\n",
      "Epoch 60/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.5692 - acc: 0.7365 - val_loss: 0.5490 - val_acc: 0.7464\n",
      "\n",
      "Epoch 00060: val_loss did not improve\n",
      "Epoch 61/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.5540 - acc: 0.7447 - val_loss: 0.5377 - val_acc: 0.7506\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.54463 to 0.53768, saving model to saved_models/cnn.hdf5\n",
      "Epoch 62/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.5516 - acc: 0.7458 - val_loss: 0.5363 - val_acc: 0.7529\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.53768 to 0.53630, saving model to saved_models/cnn.hdf5\n",
      "Epoch 63/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.5500 - acc: 0.7450 - val_loss: 0.5623 - val_acc: 0.7387\n",
      "\n",
      "Epoch 00063: val_loss did not improve\n",
      "Epoch 64/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.5498 - acc: 0.7455 - val_loss: 0.5417 - val_acc: 0.7488\n",
      "\n",
      "Epoch 00064: val_loss did not improve\n",
      "Epoch 65/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.5592 - acc: 0.7421 - val_loss: 0.5289 - val_acc: 0.7505\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.53630 to 0.52891, saving model to saved_models/cnn.hdf5\n",
      "Epoch 66/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.5462 - acc: 0.7474 - val_loss: 0.5583 - val_acc: 0.7453\n",
      "\n",
      "Epoch 00066: val_loss did not improve\n",
      "Epoch 67/200\n",
      "57600/57600 [==============================] - 14s 247us/step - loss: 0.5372 - acc: 0.7499 - val_loss: 0.5308 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00067: val_loss did not improve\n",
      "Epoch 68/200\n",
      "57600/57600 [==============================] - 14s 248us/step - loss: 0.5414 - acc: 0.7489 - val_loss: 0.5430 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00068: val_loss did not improve\n",
      "Epoch 69/200\n",
      "57600/57600 [==============================] - 14s 250us/step - loss: 0.5380 - acc: 0.7515 - val_loss: 0.5203 - val_acc: 0.7579\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.52891 to 0.52026, saving model to saved_models/cnn.hdf5\n",
      "Epoch 70/200\n",
      "57600/57600 [==============================] - 14s 248us/step - loss: 0.5364 - acc: 0.7504 - val_loss: 0.5253 - val_acc: 0.7604\n",
      "\n",
      "Epoch 00070: val_loss did not improve\n",
      "Epoch 71/200\n",
      "57600/57600 [==============================] - 14s 248us/step - loss: 0.5240 - acc: 0.7558 - val_loss: 0.5155 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.52026 to 0.51547, saving model to saved_models/cnn.hdf5\n",
      "Epoch 72/200\n",
      "57600/57600 [==============================] - 14s 248us/step - loss: 0.5330 - acc: 0.7529 - val_loss: 0.5150 - val_acc: 0.7597\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.51547 to 0.51497, saving model to saved_models/cnn.hdf5\n",
      "Epoch 73/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.5278 - acc: 0.7540 - val_loss: 0.5179 - val_acc: 0.7599\n",
      "\n",
      "Epoch 00073: val_loss did not improve\n",
      "Epoch 74/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.5300 - acc: 0.7550 - val_loss: 0.5164 - val_acc: 0.7618\n",
      "\n",
      "Epoch 00074: val_loss did not improve\n",
      "Epoch 75/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.5139 - acc: 0.7624 - val_loss: 0.5073 - val_acc: 0.7630\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.51497 to 0.50727, saving model to saved_models/cnn.hdf5\n",
      "Epoch 76/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.5149 - acc: 0.7617 - val_loss: 0.5135 - val_acc: 0.7613\n",
      "\n",
      "Epoch 00076: val_loss did not improve\n",
      "Epoch 77/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.5173 - acc: 0.7595 - val_loss: 0.5048 - val_acc: 0.7642\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.50727 to 0.50485, saving model to saved_models/cnn.hdf5\n",
      "Epoch 78/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.5164 - acc: 0.7585 - val_loss: 0.5234 - val_acc: 0.7606\n",
      "\n",
      "Epoch 00078: val_loss did not improve\n",
      "Epoch 79/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.5104 - acc: 0.7631 - val_loss: 0.5128 - val_acc: 0.7595\n",
      "\n",
      "Epoch 00079: val_loss did not improve\n",
      "Epoch 80/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.5175 - acc: 0.7607 - val_loss: 0.5354 - val_acc: 0.7548\n",
      "\n",
      "Epoch 00080: val_loss did not improve\n",
      "Epoch 81/200\n",
      "57600/57600 [==============================] - 14s 243us/step - loss: 0.5109 - acc: 0.7610 - val_loss: 0.5135 - val_acc: 0.7601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00081: val_loss did not improve\n",
      "Epoch 82/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.5106 - acc: 0.7617 - val_loss: 0.5100 - val_acc: 0.7612\n",
      "\n",
      "Epoch 00082: val_loss did not improve\n",
      "Epoch 83/200\n",
      "57600/57600 [==============================] - 14s 243us/step - loss: 0.5055 - acc: 0.7644 - val_loss: 0.4915 - val_acc: 0.7746\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.50485 to 0.49154, saving model to saved_models/cnn.hdf5\n",
      "Epoch 84/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.5025 - acc: 0.7668 - val_loss: 0.5269 - val_acc: 0.7558\n",
      "\n",
      "Epoch 00084: val_loss did not improve\n",
      "Epoch 85/200\n",
      "57600/57600 [==============================] - 14s 243us/step - loss: 0.5389 - acc: 0.7522 - val_loss: 0.4998 - val_acc: 0.7702\n",
      "\n",
      "Epoch 00085: val_loss did not improve\n",
      "Epoch 86/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.5014 - acc: 0.7654 - val_loss: 0.5040 - val_acc: 0.7635\n",
      "\n",
      "Epoch 00086: val_loss did not improve\n",
      "Epoch 87/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.5008 - acc: 0.7648 - val_loss: 0.5166 - val_acc: 0.7592\n",
      "\n",
      "Epoch 00087: val_loss did not improve\n",
      "Epoch 88/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.5024 - acc: 0.7676 - val_loss: 0.4980 - val_acc: 0.7681\n",
      "\n",
      "Epoch 00088: val_loss did not improve\n",
      "Epoch 89/200\n",
      "57600/57600 [==============================] - 14s 248us/step - loss: 0.5053 - acc: 0.7657 - val_loss: 0.5055 - val_acc: 0.7687\n",
      "\n",
      "Epoch 00089: val_loss did not improve\n",
      "Epoch 90/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4971 - acc: 0.7685 - val_loss: 0.4954 - val_acc: 0.7690\n",
      "\n",
      "Epoch 00090: val_loss did not improve\n",
      "Epoch 91/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.5009 - acc: 0.7665 - val_loss: 0.5215 - val_acc: 0.7634\n",
      "\n",
      "Epoch 00091: val_loss did not improve\n",
      "Epoch 92/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.4971 - acc: 0.7684 - val_loss: 0.5147 - val_acc: 0.7586\n",
      "\n",
      "Epoch 00092: val_loss did not improve\n",
      "Epoch 93/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4939 - acc: 0.7678 - val_loss: 0.4975 - val_acc: 0.7668\n",
      "\n",
      "Epoch 00093: val_loss did not improve\n",
      "Epoch 94/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.4864 - acc: 0.7714 - val_loss: 0.4838 - val_acc: 0.7740\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.49154 to 0.48379, saving model to saved_models/cnn.hdf5\n",
      "Epoch 95/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.4895 - acc: 0.7717 - val_loss: 0.4870 - val_acc: 0.7746\n",
      "\n",
      "Epoch 00095: val_loss did not improve\n",
      "Epoch 96/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4981 - acc: 0.7686 - val_loss: 0.4899 - val_acc: 0.7726\n",
      "\n",
      "Epoch 00096: val_loss did not improve\n",
      "Epoch 97/200\n",
      "57600/57600 [==============================] - 14s 243us/step - loss: 0.4862 - acc: 0.7736 - val_loss: 0.4871 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00097: val_loss did not improve\n",
      "Epoch 98/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.4929 - acc: 0.7696 - val_loss: 0.4893 - val_acc: 0.7692\n",
      "\n",
      "Epoch 00098: val_loss did not improve\n",
      "Epoch 99/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.4918 - acc: 0.7718 - val_loss: 0.5040 - val_acc: 0.7613\n",
      "\n",
      "Epoch 00099: val_loss did not improve\n",
      "Epoch 100/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.4805 - acc: 0.7755 - val_loss: 0.4927 - val_acc: 0.7688\n",
      "\n",
      "Epoch 00100: val_loss did not improve\n",
      "Epoch 101/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.4902 - acc: 0.7697 - val_loss: 0.5072 - val_acc: 0.7659\n",
      "\n",
      "Epoch 00101: val_loss did not improve\n",
      "Epoch 102/200\n",
      "57600/57600 [==============================] - 14s 243us/step - loss: 0.4809 - acc: 0.7752 - val_loss: 0.4798 - val_acc: 0.7797\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.48379 to 0.47978, saving model to saved_models/cnn.hdf5\n",
      "Epoch 103/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.4873 - acc: 0.7736 - val_loss: 0.4765 - val_acc: 0.7826\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.47978 to 0.47654, saving model to saved_models/cnn.hdf5\n",
      "Epoch 104/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.4862 - acc: 0.7740 - val_loss: 0.5303 - val_acc: 0.7553\n",
      "\n",
      "Epoch 00104: val_loss did not improve\n",
      "Epoch 105/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4756 - acc: 0.7774 - val_loss: 0.4785 - val_acc: 0.7776\n",
      "\n",
      "Epoch 00105: val_loss did not improve\n",
      "Epoch 106/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4787 - acc: 0.7765 - val_loss: 0.4778 - val_acc: 0.7760\n",
      "\n",
      "Epoch 00106: val_loss did not improve\n",
      "Epoch 107/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4774 - acc: 0.7785 - val_loss: 0.4865 - val_acc: 0.7758\n",
      "\n",
      "Epoch 00107: val_loss did not improve\n",
      "Epoch 108/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4803 - acc: 0.7767 - val_loss: 0.5245 - val_acc: 0.7584\n",
      "\n",
      "Epoch 00108: val_loss did not improve\n",
      "Epoch 109/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4775 - acc: 0.7785 - val_loss: 0.4712 - val_acc: 0.7783\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.47654 to 0.47116, saving model to saved_models/cnn.hdf5\n",
      "Epoch 110/200\n",
      "57600/57600 [==============================] - 14s 243us/step - loss: 0.4809 - acc: 0.7763 - val_loss: 0.4822 - val_acc: 0.7767\n",
      "\n",
      "Epoch 00110: val_loss did not improve\n",
      "Epoch 111/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4733 - acc: 0.7783 - val_loss: 0.5195 - val_acc: 0.7648\n",
      "\n",
      "Epoch 00111: val_loss did not improve\n",
      "Epoch 112/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.4740 - acc: 0.7817 - val_loss: 0.4811 - val_acc: 0.7797\n",
      "\n",
      "Epoch 00112: val_loss did not improve\n",
      "Epoch 113/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4778 - acc: 0.7781 - val_loss: 0.4777 - val_acc: 0.7792\n",
      "\n",
      "Epoch 00113: val_loss did not improve\n",
      "Epoch 114/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.4763 - acc: 0.7773 - val_loss: 0.4732 - val_acc: 0.7825\n",
      "\n",
      "Epoch 00114: val_loss did not improve\n",
      "Epoch 115/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4629 - acc: 0.7819 - val_loss: 0.4857 - val_acc: 0.7798\n",
      "\n",
      "Epoch 00115: val_loss did not improve\n",
      "Epoch 116/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.4674 - acc: 0.7824 - val_loss: 0.4632 - val_acc: 0.7858\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.47116 to 0.46320, saving model to saved_models/cnn.hdf5\n",
      "Epoch 117/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.4637 - acc: 0.7837 - val_loss: 0.4773 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00117: val_loss did not improve\n",
      "Epoch 118/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.4624 - acc: 0.7864 - val_loss: 0.4840 - val_acc: 0.7735\n",
      "\n",
      "Epoch 00118: val_loss did not improve\n",
      "Epoch 119/200\n",
      "57600/57600 [==============================] - 14s 243us/step - loss: 0.4591 - acc: 0.7855 - val_loss: 0.4749 - val_acc: 0.7810\n",
      "\n",
      "Epoch 00119: val_loss did not improve\n",
      "Epoch 120/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.4640 - acc: 0.7852 - val_loss: 0.4751 - val_acc: 0.7835\n",
      "\n",
      "Epoch 00120: val_loss did not improve\n",
      "Epoch 121/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.4646 - acc: 0.7844 - val_loss: 0.4704 - val_acc: 0.7835\n",
      "\n",
      "Epoch 00121: val_loss did not improve\n",
      "Epoch 122/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.4622 - acc: 0.7849 - val_loss: 0.4911 - val_acc: 0.7776\n",
      "\n",
      "Epoch 00122: val_loss did not improve\n",
      "Epoch 123/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4567 - acc: 0.7873 - val_loss: 0.4635 - val_acc: 0.7856\n",
      "\n",
      "Epoch 00123: val_loss did not improve\n",
      "Epoch 124/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.4580 - acc: 0.7866 - val_loss: 0.4690 - val_acc: 0.7816\n",
      "\n",
      "Epoch 00124: val_loss did not improve\n",
      "Epoch 125/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.4554 - acc: 0.7891 - val_loss: 0.4672 - val_acc: 0.7866\n",
      "\n",
      "Epoch 00125: val_loss did not improve\n",
      "Epoch 126/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.4585 - acc: 0.7866 - val_loss: 0.4633 - val_acc: 0.7870\n",
      "\n",
      "Epoch 00126: val_loss did not improve\n",
      "Epoch 127/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.4687 - acc: 0.7825 - val_loss: 0.4547 - val_acc: 0.7905\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.46320 to 0.45473, saving model to saved_models/cnn.hdf5\n",
      "Epoch 128/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4483 - acc: 0.7922 - val_loss: 0.4627 - val_acc: 0.7870\n",
      "\n",
      "Epoch 00128: val_loss did not improve\n",
      "Epoch 129/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4498 - acc: 0.7915 - val_loss: 0.4920 - val_acc: 0.7781\n",
      "\n",
      "Epoch 00129: val_loss did not improve\n",
      "Epoch 130/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.4559 - acc: 0.7874 - val_loss: 0.4738 - val_acc: 0.7869\n",
      "\n",
      "Epoch 00130: val_loss did not improve\n",
      "Epoch 131/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.4463 - acc: 0.7936 - val_loss: 0.4589 - val_acc: 0.7926\n",
      "\n",
      "Epoch 00131: val_loss did not improve\n",
      "Epoch 132/200\n",
      "57600/57600 [==============================] - 14s 243us/step - loss: 0.4503 - acc: 0.7923 - val_loss: 0.4835 - val_acc: 0.7837\n",
      "\n",
      "Epoch 00132: val_loss did not improve\n",
      "Epoch 133/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4442 - acc: 0.7945 - val_loss: 0.4466 - val_acc: 0.7980\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.45473 to 0.44662, saving model to saved_models/cnn.hdf5\n",
      "Epoch 134/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.4474 - acc: 0.7932 - val_loss: 0.4647 - val_acc: 0.7917\n",
      "\n",
      "Epoch 00134: val_loss did not improve\n",
      "Epoch 135/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.4458 - acc: 0.7942 - val_loss: 0.4493 - val_acc: 0.7985\n",
      "\n",
      "Epoch 00135: val_loss did not improve\n",
      "Epoch 136/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4383 - acc: 0.7969 - val_loss: 0.4779 - val_acc: 0.7846\n",
      "\n",
      "Epoch 00136: val_loss did not improve\n",
      "Epoch 137/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4390 - acc: 0.7983 - val_loss: 0.4481 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00137: val_loss did not improve\n",
      "Epoch 138/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.4514 - acc: 0.7929 - val_loss: 0.4660 - val_acc: 0.7872\n",
      "\n",
      "Epoch 00138: val_loss did not improve\n",
      "Epoch 139/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4331 - acc: 0.7998 - val_loss: 0.4542 - val_acc: 0.7935\n",
      "\n",
      "Epoch 00139: val_loss did not improve\n",
      "Epoch 140/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4322 - acc: 0.8002 - val_loss: 0.4576 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00140: val_loss did not improve\n",
      "Epoch 141/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4382 - acc: 0.7968 - val_loss: 0.4458 - val_acc: 0.7977\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.44662 to 0.44581, saving model to saved_models/cnn.hdf5\n",
      "Epoch 142/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.4306 - acc: 0.7986 - val_loss: 0.4475 - val_acc: 0.7976\n",
      "\n",
      "Epoch 00142: val_loss did not improve\n",
      "Epoch 143/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4370 - acc: 0.7976 - val_loss: 0.4486 - val_acc: 0.7983\n",
      "\n",
      "Epoch 00143: val_loss did not improve\n",
      "Epoch 144/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4312 - acc: 0.7995 - val_loss: 0.4506 - val_acc: 0.7967\n",
      "\n",
      "Epoch 00144: val_loss did not improve\n",
      "Epoch 145/200\n",
      "57600/57600 [==============================] - 14s 247us/step - loss: 0.4361 - acc: 0.7984 - val_loss: 0.4441 - val_acc: 0.7969\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.44581 to 0.44409, saving model to saved_models/cnn.hdf5\n",
      "Epoch 146/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.4309 - acc: 0.8007 - val_loss: 0.4644 - val_acc: 0.7934\n",
      "\n",
      "Epoch 00146: val_loss did not improve\n",
      "Epoch 147/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.4315 - acc: 0.8017 - val_loss: 0.4530 - val_acc: 0.7965\n",
      "\n",
      "Epoch 00147: val_loss did not improve\n",
      "Epoch 148/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4261 - acc: 0.8023 - val_loss: 0.4502 - val_acc: 0.7958\n",
      "\n",
      "Epoch 00148: val_loss did not improve\n",
      "Epoch 149/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4268 - acc: 0.8016 - val_loss: 0.4432 - val_acc: 0.8015\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.44409 to 0.44323, saving model to saved_models/cnn.hdf5\n",
      "Epoch 150/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.4277 - acc: 0.8036 - val_loss: 0.4811 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00150: val_loss did not improve\n",
      "Epoch 151/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.4254 - acc: 0.8017 - val_loss: 0.4471 - val_acc: 0.7996\n",
      "\n",
      "Epoch 00151: val_loss did not improve\n",
      "Epoch 152/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4235 - acc: 0.8019 - val_loss: 0.4465 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00152: val_loss did not improve\n",
      "Epoch 153/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.4209 - acc: 0.8051 - val_loss: 0.4359 - val_acc: 0.8022\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.44323 to 0.43591, saving model to saved_models/cnn.hdf5\n",
      "Epoch 154/200\n",
      "57600/57600 [==============================] - 14s 243us/step - loss: 0.4213 - acc: 0.8030 - val_loss: 0.4356 - val_acc: 0.8073\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.43591 to 0.43558, saving model to saved_models/cnn.hdf5\n",
      "Epoch 155/200\n",
      "57600/57600 [==============================] - 14s 243us/step - loss: 0.4185 - acc: 0.8034 - val_loss: 0.4279 - val_acc: 0.8028\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.43558 to 0.42793, saving model to saved_models/cnn.hdf5\n",
      "Epoch 156/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4230 - acc: 0.8038 - val_loss: 0.4269 - val_acc: 0.8044\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.42793 to 0.42685, saving model to saved_models/cnn.hdf5\n",
      "Epoch 157/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4180 - acc: 0.8054 - val_loss: 0.4438 - val_acc: 0.7989\n",
      "\n",
      "Epoch 00157: val_loss did not improve\n",
      "Epoch 158/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.4193 - acc: 0.8044 - val_loss: 0.4407 - val_acc: 0.7993\n",
      "\n",
      "Epoch 00158: val_loss did not improve\n",
      "Epoch 159/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.4160 - acc: 0.8077 - val_loss: 0.4244 - val_acc: 0.8084\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.42685 to 0.42445, saving model to saved_models/cnn.hdf5\n",
      "Epoch 160/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.4128 - acc: 0.8081 - val_loss: 0.4638 - val_acc: 0.7946\n",
      "\n",
      "Epoch 00160: val_loss did not improve\n",
      "Epoch 161/200\n",
      "57600/57600 [==============================] - 14s 243us/step - loss: 0.4143 - acc: 0.8072 - val_loss: 0.4334 - val_acc: 0.8082\n",
      "\n",
      "Epoch 00161: val_loss did not improve\n",
      "Epoch 162/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.4142 - acc: 0.8068 - val_loss: 0.4186 - val_acc: 0.8123\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.42445 to 0.41856, saving model to saved_models/cnn.hdf5\n",
      "Epoch 163/200\n",
      "57600/57600 [==============================] - 14s 248us/step - loss: 0.4145 - acc: 0.8068 - val_loss: 0.4271 - val_acc: 0.8067\n",
      "\n",
      "Epoch 00163: val_loss did not improve\n",
      "Epoch 164/200\n",
      "57600/57600 [==============================] - 14s 249us/step - loss: 0.4183 - acc: 0.8049 - val_loss: 0.4227 - val_acc: 0.8093\n",
      "\n",
      "Epoch 00164: val_loss did not improve\n",
      "Epoch 165/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4066 - acc: 0.8098 - val_loss: 0.4525 - val_acc: 0.7972\n",
      "\n",
      "Epoch 00165: val_loss did not improve\n",
      "Epoch 166/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.4055 - acc: 0.8108 - val_loss: 0.4270 - val_acc: 0.8061\n",
      "\n",
      "Epoch 00166: val_loss did not improve\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4148 - acc: 0.8065 - val_loss: 0.4329 - val_acc: 0.8069\n",
      "\n",
      "Epoch 00167: val_loss did not improve\n",
      "Epoch 168/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4062 - acc: 0.8098 - val_loss: 0.4188 - val_acc: 0.8104\n",
      "\n",
      "Epoch 00168: val_loss did not improve\n",
      "Epoch 169/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.4043 - acc: 0.8098 - val_loss: 0.4552 - val_acc: 0.8008\n",
      "\n",
      "Epoch 00169: val_loss did not improve\n",
      "Epoch 170/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4053 - acc: 0.8107 - val_loss: 0.4224 - val_acc: 0.8101\n",
      "\n",
      "Epoch 00170: val_loss did not improve\n",
      "Epoch 171/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.4058 - acc: 0.8108 - val_loss: 0.4274 - val_acc: 0.8085\n",
      "\n",
      "Epoch 00171: val_loss did not improve\n",
      "Epoch 172/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.4071 - acc: 0.8100 - val_loss: 0.4420 - val_acc: 0.8026\n",
      "\n",
      "Epoch 00172: val_loss did not improve\n",
      "Epoch 173/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4014 - acc: 0.8116 - val_loss: 0.4173 - val_acc: 0.8111\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.41856 to 0.41733, saving model to saved_models/cnn.hdf5\n",
      "Epoch 174/200\n",
      "57600/57600 [==============================] - 14s 247us/step - loss: 0.3981 - acc: 0.8133 - val_loss: 0.4305 - val_acc: 0.8075\n",
      "\n",
      "Epoch 00174: val_loss did not improve\n",
      "Epoch 175/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4051 - acc: 0.8122 - val_loss: 0.4186 - val_acc: 0.8118\n",
      "\n",
      "Epoch 00175: val_loss did not improve\n",
      "Epoch 176/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.3993 - acc: 0.8140 - val_loss: 0.4317 - val_acc: 0.8083\n",
      "\n",
      "Epoch 00176: val_loss did not improve\n",
      "Epoch 177/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.4090 - acc: 0.8084 - val_loss: 0.4148 - val_acc: 0.8126\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.41733 to 0.41476, saving model to saved_models/cnn.hdf5\n",
      "Epoch 178/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.3999 - acc: 0.8129 - val_loss: 0.4247 - val_acc: 0.8071\n",
      "\n",
      "Epoch 00178: val_loss did not improve\n",
      "Epoch 179/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.3962 - acc: 0.8148 - val_loss: 0.4259 - val_acc: 0.8101\n",
      "\n",
      "Epoch 00179: val_loss did not improve\n",
      "Epoch 180/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.4053 - acc: 0.8109 - val_loss: 0.4267 - val_acc: 0.8085\n",
      "\n",
      "Epoch 00180: val_loss did not improve\n",
      "Epoch 181/200\n",
      "57600/57600 [==============================] - 14s 247us/step - loss: 0.3967 - acc: 0.8162 - val_loss: 0.4184 - val_acc: 0.8113\n",
      "\n",
      "Epoch 00181: val_loss did not improve\n",
      "Epoch 182/200\n",
      "57600/57600 [==============================] - 14s 247us/step - loss: 0.3976 - acc: 0.8146 - val_loss: 0.4170 - val_acc: 0.8118\n",
      "\n",
      "Epoch 00182: val_loss did not improve\n",
      "Epoch 183/200\n",
      "57600/57600 [==============================] - 14s 248us/step - loss: 0.3944 - acc: 0.8168 - val_loss: 0.4121 - val_acc: 0.8129\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.41476 to 0.41207, saving model to saved_models/cnn.hdf5\n",
      "Epoch 184/200\n",
      "57600/57600 [==============================] - 14s 251us/step - loss: 0.3956 - acc: 0.8131 - val_loss: 0.4232 - val_acc: 0.8097\n",
      "\n",
      "Epoch 00184: val_loss did not improve\n",
      "Epoch 185/200\n",
      "57600/57600 [==============================] - 14s 248us/step - loss: 0.3950 - acc: 0.8146 - val_loss: 0.4313 - val_acc: 0.7999\n",
      "\n",
      "Epoch 00185: val_loss did not improve\n",
      "Epoch 186/200\n",
      "57600/57600 [==============================] - 14s 247us/step - loss: 0.3928 - acc: 0.8166 - val_loss: 0.4404 - val_acc: 0.8001\n",
      "\n",
      "Epoch 00186: val_loss did not improve\n",
      "Epoch 187/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.3940 - acc: 0.8158 - val_loss: 0.4275 - val_acc: 0.8078\n",
      "\n",
      "Epoch 00187: val_loss did not improve\n",
      "Epoch 188/200\n",
      "57600/57600 [==============================] - 14s 247us/step - loss: 0.3901 - acc: 0.8171 - val_loss: 0.4235 - val_acc: 0.8103\n",
      "\n",
      "Epoch 00188: val_loss did not improve\n",
      "Epoch 189/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.3935 - acc: 0.8149 - val_loss: 0.4204 - val_acc: 0.8118\n",
      "\n",
      "Epoch 00189: val_loss did not improve\n",
      "Epoch 190/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.3909 - acc: 0.8167 - val_loss: 0.4123 - val_acc: 0.8140\n",
      "\n",
      "Epoch 00190: val_loss did not improve\n",
      "Epoch 191/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.3912 - acc: 0.8163 - val_loss: 0.4388 - val_acc: 0.7974\n",
      "\n",
      "Epoch 00191: val_loss did not improve\n",
      "Epoch 192/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.3921 - acc: 0.8163 - val_loss: 0.4076 - val_acc: 0.8151\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.41207 to 0.40758, saving model to saved_models/cnn.hdf5\n",
      "Epoch 193/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.3890 - acc: 0.8163 - val_loss: 0.4184 - val_acc: 0.8121\n",
      "\n",
      "Epoch 00193: val_loss did not improve\n",
      "Epoch 194/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.3863 - acc: 0.8185 - val_loss: 0.4345 - val_acc: 0.8072\n",
      "\n",
      "Epoch 00194: val_loss did not improve\n",
      "Epoch 195/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.3855 - acc: 0.8194 - val_loss: 0.4181 - val_acc: 0.8119\n",
      "\n",
      "Epoch 00195: val_loss did not improve\n",
      "Epoch 196/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.3915 - acc: 0.8166 - val_loss: 0.4149 - val_acc: 0.8138\n",
      "\n",
      "Epoch 00196: val_loss did not improve\n",
      "Epoch 197/200\n",
      "57600/57600 [==============================] - 14s 245us/step - loss: 0.3958 - acc: 0.8156 - val_loss: 0.4191 - val_acc: 0.8094\n",
      "\n",
      "Epoch 00197: val_loss did not improve\n",
      "Epoch 198/200\n",
      "57600/57600 [==============================] - 14s 247us/step - loss: 0.3841 - acc: 0.8203 - val_loss: 0.4059 - val_acc: 0.8173\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.40758 to 0.40592, saving model to saved_models/cnn.hdf5\n",
      "Epoch 199/200\n",
      "57600/57600 [==============================] - 14s 244us/step - loss: 0.3866 - acc: 0.8192 - val_loss: 0.4142 - val_acc: 0.8109\n",
      "\n",
      "Epoch 00199: val_loss did not improve\n",
      "Epoch 200/200\n",
      "57600/57600 [==============================] - 14s 246us/step - loss: 0.3931 - acc: 0.8158 - val_loss: 0.4267 - val_acc: 0.8090\n",
      "\n",
      "Epoch 00200: val_loss did not improve\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='saved_models/cnn.hdf5', verbose=1, save_best_only=True)\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=80,\n",
    "                    epochs=200,\n",
    "                    validation_data=[x_test,y_test],\n",
    "                    callbacks=[checkpointer],\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('cnn_history.json', 'w') as outfile:  \n",
    "    json.dump(history.history, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f20d3d54780>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f20d3d54f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
